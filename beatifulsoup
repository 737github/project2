
from bs4 import BeautifulSoup
from urllib.request import urlopen
from urllib.error import HTTPError

"""
#Added exception catch
# @1:if prompted userWarning: No parser was explicitly specified,xxxxx--->add"html.parser"
def getTitle(url):
    try:
        html = urlopen(url)
    except HTTPError as e:
        return None
    try:
        bsobj = BeautifulSoup(html.read(), "html.parser") # @1
        title = bsobj.body.h1
    except AttributeError as e:
        return None
    return title
title = getTitle("http://www.pythonscraping.com/pages/page1.html")
if title == None:
    print("Title could not be found,please verify the url!")
else:
    print(title)

print("------------------------------------------------------------------------")


#Get all names based on the tag,attribute
# @2:.findall("span", {"class":"green"}) or .findall("span", {"class": {"green","red"}}) or .......
html = urlopen("http://www.pythonscraping.com/pages/warandpeace.html")
bsobj2 = BeautifulSoup(html.read(), "html.parser")
namelist = bsobj2.find_all("span", {"class":"green"}) #check soure code from Google browser @2
for name in namelist:
    print(name.get_text())

print("------------------------------------------------------------------------")
"""
#Get children() or descendants() or next_siblings()
html = urlopen("http://www.pythonscraping.com/pages/page3.html")
bsObj = BeautifulSoup(html.read(), "html.parser")
for sibling in bsObj.find("table",{"id":"giftList"}).tr.next_siblings:
    print(sibling)



